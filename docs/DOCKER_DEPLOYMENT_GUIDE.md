# ğŸ³ Dockeréƒ¨ç½²æŒ‡å— - ç¬¬ä¸‰æ–¹æœåŠ¡å®¹å™¨åŒ–

**åˆ›å»ºæ—¥æœŸ**: 2026-01-17  
**ç‰ˆæœ¬**: v1.0  
**åŸåˆ™**: æ‰€æœ‰ç¬¬ä¸‰æ–¹æ•°æ®åº“å’Œå·¥å…·ä½¿ç”¨Dockerï¼Œé¿å…æœ¬åœ°å®‰è£…  

---

## ğŸ“‹ ç›®å½•

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [æœåŠ¡æ¸…å•](#æœåŠ¡æ¸…å•)
3. [Docker Composeé…ç½®](#docker-composeé…ç½®)
4. [åˆ†é˜¶æ®µéƒ¨ç½²](#åˆ†é˜¶æ®µéƒ¨ç½²)
5. [æœåŠ¡è¯¦ç»†é…ç½®](#æœåŠ¡è¯¦ç»†é…ç½®)
6. [ç½‘ç»œé…ç½®](#ç½‘ç»œé…ç½®)
7. [æ•°æ®æŒä¹…åŒ–](#æ•°æ®æŒä¹…åŒ–)
8. [å¥åº·æ£€æŸ¥](#å¥åº·æ£€æŸ¥)
9. [ä½¿ç”¨æŒ‡å—](#ä½¿ç”¨æŒ‡å—)

---

## ğŸ¯ æ¦‚è¿°

### è®¾è®¡åŸåˆ™

1. **é›¶æœ¬åœ°å®‰è£…**: æ‰€æœ‰ç¬¬ä¸‰æ–¹æœåŠ¡ä½¿ç”¨Dockerå®¹å™¨
2. **ä¸€é”®å¯åŠ¨**: docker-composeä¸€é”®å¯åŠ¨æ‰€æœ‰æœåŠ¡
3. **æ•°æ®æŒä¹…åŒ–**: ä½¿ç”¨Docker volumesæŒä¹…åŒ–æ•°æ®
4. **å¼€å‘å‹å¥½**: æ˜ å°„ç«¯å£ä¾¿äºæœ¬åœ°å¼€å‘è°ƒè¯•
5. **ç”Ÿäº§å°±ç»ª**: é…ç½®å¯ç›´æ¥ç”¨äºç”Ÿäº§ç¯å¢ƒ

### æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Host Machine                            â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚            Docker Compose Network                    â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚  Neo4j       â”‚  â”‚ Elasticsearchâ”‚  â”‚  Redis    â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  :7474       â”‚  â”‚  :9200       â”‚  â”‚  :6379    â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚  RabbitMQ    â”‚  â”‚  Pellet      â”‚  â”‚  Jena     â”‚ â”‚   â”‚
â”‚  â”‚  â”‚  :5672,15672 â”‚  â”‚  Reasoner    â”‚  â”‚  Fuseki   â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Application (Backend + Frontend)              â”‚  â”‚
â”‚  â”‚         Backend:8090  |  Frontend:8080                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ æœåŠ¡æ¸…å•

### Sprint 03-04 æ‰€éœ€æœåŠ¡

| æœåŠ¡ | ç”¨é€” | Dockeré•œåƒ | ç«¯å£æ˜ å°„ | ä¼˜å…ˆçº§ |
|------|------|-----------|---------|--------|
| **Elasticsearch** | æ™ºèƒ½æœç´¢ã€å…¨æ–‡æ£€ç´¢ | elasticsearch:8.11.0 | 9200:9200 | P0 é«˜ |
| **Kibana** | ESå¯è§†åŒ–ç®¡ç† | kibana:8.11.0 | 5601:5601 | P1 ä¸­ |
| **Redis** | ç¼“å­˜ã€ä¼šè¯å­˜å‚¨ | redis:7-alpine | 6379:6379 | P1 ä¸­ |

### Sprint 05-06 æ‰€éœ€æœåŠ¡

| æœåŠ¡ | ç”¨é€” | Dockeré•œåƒ | ç«¯å£æ˜ å°„ | ä¼˜å…ˆçº§ |
|------|------|-----------|---------|--------|
| **Neo4j** | å›¾æ•°æ®åº“å­˜å‚¨ | neo4j:5.15-community | 7474:7474, 7687:7687 | P0 é«˜ |
| **Apache Jena Fuseki** | RDFå­˜å‚¨ã€SPARQLæŸ¥è¯¢ | stain/jena-fuseki | 3030:3030 | P0 é«˜ |
| **RabbitMQ** | æ¶ˆæ¯é˜Ÿåˆ— | rabbitmq:3-management | 5672:5672, 15672:15672 | P1 ä¸­ |

### å¯é€‰æœåŠ¡ï¼ˆæŒ‰éœ€ï¼‰

| æœåŠ¡ | ç”¨é€” | Dockeré•œåƒ | ç«¯å£æ˜ å°„ | ä¼˜å…ˆçº§ |
|------|------|-----------|---------|--------|
| **PostgreSQL** | å…³ç³»å‹æ•°æ®åº“ | postgres:16-alpine | 5432:5432 | P2 ä½ |
| **MinIO** | å¯¹è±¡å­˜å‚¨ï¼ˆS3å…¼å®¹ï¼‰ | minio/minio | 9000:9000, 9001:9001 | P2 ä½ |
| **Grafana** | ç›‘æ§å¯è§†åŒ– | grafana/grafana | 3000:3000 | P3 ä½ |

---

## ğŸ‹ Docker Composeé…ç½®

### åŸºç¡€é…ç½®æ–‡ä»¶

åˆ›å»º `docker-compose.yml`:

```yaml
version: '3.8'

services:
  # ==================== Sprint 03-04 æœåŠ¡ ====================
  
  # Elasticsearch - æ™ºèƒ½æœç´¢
  elasticsearch:
    image: elasticsearch:8.11.0
    container_name: onto-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - bootstrap.memory_lock=true
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - es-data:/usr/share/elasticsearch/data
    networks:
      - onto-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # Kibana - ESå¯è§†åŒ–
  kibana:
    image: kibana:8.11.0
    container_name: onto-kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - onto-network
    restart: unless-stopped

  # Redis - ç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: onto-redis
    command: redis-server --appendonly yes
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - onto-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    restart: unless-stopped

  # ==================== Sprint 05-06 æœåŠ¡ ====================
  
  # Neo4j - å›¾æ•°æ®åº“
  neo4j:
    image: neo4j:5.15-community
    container_name: onto-neo4j
    environment:
      - NEO4J_AUTH=neo4j/password123
      - NEO4J_dbms_memory_pagecache_size=512M
      - NEO4J_dbms_memory_heap_initial__size=512M
      - NEO4J_dbms_memory_heap_max__size=2G
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs
      - neo4j-import:/var/lib/neo4j/import
      - neo4j-plugins:/plugins
    networks:
      - onto-network
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:7474 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # Apache Jena Fuseki - RDFå­˜å‚¨
  jena-fuseki:
    image: stain/jena-fuseki
    container_name: onto-jena-fuseki
    environment:
      - ADMIN_PASSWORD=admin123
      - JVM_ARGS=-Xmx2g
    ports:
      - "3030:3030"
    volumes:
      - fuseki-data:/fuseki
    networks:
      - onto-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3030/$/ping || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # RabbitMQ - æ¶ˆæ¯é˜Ÿåˆ—
  rabbitmq:
    image: rabbitmq:3-management
    container_name: onto-rabbitmq
    environment:
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS=admin123
    ports:
      - "5672:5672"   # AMQP
      - "15672:15672" # Management UI
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    networks:
      - onto-network
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # ==================== å¯é€‰æœåŠ¡ ====================
  
  # PostgreSQL - å…³ç³»å‹æ•°æ®åº“
  postgres:
    image: postgres:16-alpine
    container_name: onto-postgres
    environment:
      - POSTGRES_USER=onto
      - POSTGRES_PASSWORD=onto123
      - POSTGRES_DB=ontology
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - onto-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U onto"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # MinIO - å¯¹è±¡å­˜å‚¨
  minio:
    image: minio/minio
    container_name: onto-minio
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin123
    ports:
      - "9000:9000"  # API
      - "9001:9001"  # Console
    volumes:
      - minio-data:/data
    networks:
      - onto-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

# ç½‘ç»œé…ç½®
networks:
  onto-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16

# æ•°æ®å·
volumes:
  es-data:
    driver: local
  redis-data:
    driver: local
  neo4j-data:
    driver: local
  neo4j-logs:
    driver: local
  neo4j-import:
    driver: local
  neo4j-plugins:
    driver: local
  fuseki-data:
    driver: local
  rabbitmq-data:
    driver: local
  postgres-data:
    driver: local
  minio-data:
    driver: local
```

---

## ğŸ“… åˆ†é˜¶æ®µéƒ¨ç½²

### Sprint 03: æ™ºèƒ½æœç´¢ï¼ˆæœ€å°é…ç½®ï¼‰

åˆ›å»º `docker-compose.sprint03.yml`:

```yaml
version: '3.8'

services:
  # ä»…å¯åŠ¨Sprint 03æ‰€éœ€æœåŠ¡
  elasticsearch:
    extends:
      file: docker-compose.yml
      service: elasticsearch
  
  kibana:
    extends:
      file: docker-compose.yml
      service: kibana
  
  redis:
    extends:
      file: docker-compose.yml
      service: redis

networks:
  onto-network:
    driver: bridge

volumes:
  es-data:
  redis-data:
```

**å¯åŠ¨å‘½ä»¤**:
```bash
docker-compose -f docker-compose.sprint03.yml up -d
```

### Sprint 05: å›¾æ•°æ®åº“+æ¨ç†

åˆ›å»º `docker-compose.sprint05.yml`:

```yaml
version: '3.8'

services:
  # Sprint 03 æœåŠ¡
  elasticsearch:
    extends:
      file: docker-compose.yml
      service: elasticsearch
  
  redis:
    extends:
      file: docker-compose.yml
      service: redis
  
  # Sprint 05 æ–°å¢æœåŠ¡
  neo4j:
    extends:
      file: docker-compose.yml
      service: neo4j
  
  jena-fuseki:
    extends:
      file: docker-compose.yml
      service: jena-fuseki
  
  rabbitmq:
    extends:
      file: docker-compose.yml
      service: rabbitmq

networks:
  onto-network:
    driver: bridge

volumes:
  es-data:
  redis-data:
  neo4j-data:
  neo4j-logs:
  neo4j-import:
  neo4j-plugins:
  fuseki-data:
  rabbitmq-data:
```

**å¯åŠ¨å‘½ä»¤**:
```bash
docker-compose -f docker-compose.sprint05.yml up -d
```

---

## âš™ï¸ æœåŠ¡è¯¦ç»†é…ç½®

### 1. Elasticsearché…ç½®

#### æ€§èƒ½è°ƒä¼˜
```yaml
elasticsearch:
  environment:
    # å†…å­˜é…ç½®ï¼ˆæ ¹æ®æœºå™¨è°ƒæ•´ï¼‰
    - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
    
    # ç¦ç”¨å®‰å…¨ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
    - xpack.security.enabled=false
    
    # ç¦ç”¨MLï¼ˆèŠ‚çœèµ„æºï¼‰
    - xpack.ml.enabled=false
    
    # å•èŠ‚ç‚¹æ¨¡å¼
    - discovery.type=single-node
```

#### ç´¢å¼•æ¨¡æ¿
åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆ›å»ºï¼š

```javascript
// backend/src/config/elasticsearch-setup.js
const { Client } = require('@elastic/elasticsearch');

async function setupElasticsearch() {
  const client = new Client({ node: 'http://localhost:9200' });
  
  // åˆ›å»ºèŠ‚ç‚¹ç´¢å¼•
  await client.indices.create({
    index: 'ontology_nodes',
    body: {
      mappings: {
        properties: {
          id: { type: 'keyword' },
          type: { type: 'keyword' },
          label: { type: 'text', analyzer: 'standard' },
          description: { type: 'text' },
          properties: { type: 'object', enabled: true },
          created_at: { type: 'date' },
          updated_at: { type: 'date' }
        }
      }
    }
  });
}
```

### 2. Neo4jé…ç½®

#### åˆå§‹åŒ–è„šæœ¬
åˆ›å»º `docker/neo4j/init.cypher`:

```cypher
// åˆ›å»ºçº¦æŸ
CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:Entity) REQUIRE e.id IS UNIQUE;

// åˆ›å»ºç´¢å¼•
CREATE INDEX entity_type IF NOT EXISTS FOR (e:Entity) ON (e.type);
CREATE INDEX entity_label IF NOT EXISTS FOR (e:Entity) ON (e.label);

// åˆ›å»ºå…³ç³»ç±»å‹ç´¢å¼•
CREATE INDEX rel_type IF NOT EXISTS FOR ()-[r:RELATION]-() ON (r.type);
```

#### è¿æ¥é…ç½®
```javascript
// backend/src/config/neo4j.js
const neo4j = require('neo4j-driver');

const driver = neo4j.driver(
  'bolt://localhost:7687',
  neo4j.auth.basic('neo4j', 'password123'),
  {
    maxConnectionPoolSize: 50,
    connectionAcquisitionTimeout: 60000
  }
);

module.exports = driver;
```

### 3. Jena Fusekié…ç½®

#### æ•°æ®é›†åˆ›å»º
```bash
# è®¿é—®ç®¡ç†ç•Œé¢åˆ›å»ºæ•°æ®é›†
curl -X POST http://localhost:3030/$/datasets \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "dbName=ontology&dbType=tdb2"
```

#### SPARQLæŸ¥è¯¢ç¤ºä¾‹
```javascript
// backend/src/services/SPARQLService.js
const axios = require('axios');

async function querySPARQL(query) {
  const response = await axios.post(
    'http://localhost:3030/ontology/sparql',
    `query=${encodeURIComponent(query)}`,
    {
      headers: {
        'Content-Type': 'application/x-www-form-urlencoded',
        'Accept': 'application/sparql-results+json'
      }
    }
  );
  
  return response.data;
}
```

### 4. Redisé…ç½®

#### è¿æ¥é…ç½®
```javascript
// backend/src/config/redis.js
const Redis = require('ioredis');

const redis = new Redis({
  host: 'localhost',
  port: 6379,
  db: 0,
  retryStrategy(times) {
    const delay = Math.min(times * 50, 2000);
    return delay;
  }
});

module.exports = redis;
```

### 5. RabbitMQé…ç½®

#### è¿æ¥é…ç½®
```javascript
// backend/src/config/rabbitmq.js
const amqp = require('amqplib');

let connection, channel;

async function connectRabbitMQ() {
  connection = await amqp.connect('amqp://admin:admin123@localhost:5672');
  channel = await connection.createChannel();
  
  // å£°æ˜é˜Ÿåˆ—
  await channel.assertQueue('ontology_tasks', { durable: true });
  
  return channel;
}

module.exports = { connectRabbitMQ };
```

---

## ğŸŒ ç½‘ç»œé…ç½®

### æœåŠ¡é—´é€šä¿¡

```yaml
# åº”ç”¨è®¿é—®DockeræœåŠ¡
networks:
  onto-network:
    driver: bridge
```

### ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env`:

```bash
# DockeræœåŠ¡é…ç½®
ELASTICSEARCH_URL=http://localhost:9200
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password123
FUSEKI_URL=http://localhost:3030/ontology
REDIS_URL=redis://localhost:6379
RABBITMQ_URL=amqp://admin:admin123@localhost:5672

# åº”ç”¨é…ç½®
NODE_ENV=development
PORT=8090
```

---

## ğŸ’¾ æ•°æ®æŒä¹…åŒ–

### æ•°æ®å·ç®¡ç†

```bash
# æŸ¥çœ‹æ‰€æœ‰å·
docker volume ls

# æŸ¥çœ‹ç‰¹å®šå·è¯¦æƒ…
docker volume inspect onto-neo4j-data

# å¤‡ä»½å·æ•°æ®
docker run --rm -v onto-neo4j-data:/data -v $(pwd)/backup:/backup alpine tar czf /backup/neo4j-backup.tar.gz -C /data .

# æ¢å¤å·æ•°æ®
docker run --rm -v onto-neo4j-data:/data -v $(pwd)/backup:/backup alpine tar xzf /backup/neo4j-backup.tar.gz -C /data
```

### å¤‡ä»½è„šæœ¬

åˆ›å»º `scripts/backup-docker-data.sh`:

```bash
#!/bin/bash

BACKUP_DIR="./docker-backups/$(date +%Y%m%d_%H%M%S)"
mkdir -p "$BACKUP_DIR"

echo "ğŸ”„ å¼€å§‹å¤‡ä»½Dockeræ•°æ®..."

# å¤‡ä»½å„æœåŠ¡æ•°æ®
services=("neo4j-data" "es-data" "redis-data" "fuseki-data" "rabbitmq-data")

for service in "${services[@]}"; do
  echo "å¤‡ä»½ $service..."
  docker run --rm \
    -v "onto-$service:/data" \
    -v "$(pwd)/$BACKUP_DIR:/backup" \
    alpine tar czf "/backup/$service.tar.gz" -C /data .
done

echo "âœ… å¤‡ä»½å®Œæˆ: $BACKUP_DIR"
```

---

## ğŸ¥ å¥åº·æ£€æŸ¥

### ç»Ÿä¸€å¥åº·æ£€æŸ¥è„šæœ¬

åˆ›å»º `scripts/check-docker-health.sh`:

```bash
#!/bin/bash

echo "ğŸ¥ æ£€æŸ¥DockeræœåŠ¡å¥åº·çŠ¶æ€..."
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# Elasticsearch
echo -n "Elasticsearch: "
curl -s http://localhost:9200/_cluster/health | jq -r '.status' || echo "âŒ ä¸å¯ç”¨"

# Redis
echo -n "Redis: "
redis-cli ping 2>/dev/null || echo "âŒ ä¸å¯ç”¨"

# Neo4j
echo -n "Neo4j: "
curl -s http://localhost:7474 > /dev/null && echo "âœ… æ­£å¸¸" || echo "âŒ ä¸å¯ç”¨"

# Jena Fuseki
echo -n "Jena Fuseki: "
curl -s http://localhost:3030/$/ping > /dev/null && echo "âœ… æ­£å¸¸" || echo "âŒ ä¸å¯ç”¨"

# RabbitMQ
echo -n "RabbitMQ: "
curl -s -u admin:admin123 http://localhost:15672/api/overview > /dev/null && echo "âœ… æ­£å¸¸" || echo "âŒ ä¸å¯ç”¨"

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
```

---

## ğŸ“– ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿå¼€å§‹

#### 1. å®‰è£…Dockerå’ŒDocker Compose

```bash
# æ£€æŸ¥Dockerç‰ˆæœ¬
docker --version
docker-compose --version
```

#### 2. å¯åŠ¨æœåŠ¡ï¼ˆSprint 03ï¼‰

```bash
# å¯åŠ¨Sprint 03æ‰€éœ€æœåŠ¡
docker-compose -f docker-compose.sprint03.yml up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose -f docker-compose.sprint03.yml logs -f

# æ£€æŸ¥çŠ¶æ€
docker-compose -f docker-compose.sprint03.yml ps
```

#### 3. éªŒè¯æœåŠ¡

```bash
# Elasticsearch
curl http://localhost:9200

# Kibana
open http://localhost:5601

# Redis
redis-cli ping
```

#### 4. åœæ­¢æœåŠ¡

```bash
# åœæ­¢å¹¶ä¿ç•™æ•°æ®
docker-compose -f docker-compose.sprint03.yml down

# åœæ­¢å¹¶åˆ é™¤æ•°æ®
docker-compose -f docker-compose.sprint03.yml down -v
```

### å¸¸ç”¨å‘½ä»¤

```bash
# æŸ¥çœ‹æ‰€æœ‰è¿è¡Œçš„å®¹å™¨
docker ps

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs -f onto-elasticsearch

# è¿›å…¥å®¹å™¨Shell
docker exec -it onto-elasticsearch /bin/bash

# é‡å¯ç‰¹å®šæœåŠ¡
docker-compose restart elasticsearch

# æŸ¥çœ‹èµ„æºä½¿ç”¨
docker stats

# æ¸…ç†æœªä½¿ç”¨çš„èµ„æº
docker system prune -a
```

### å¼€å‘ç¯å¢ƒé…ç½®

åœ¨ `backend/.env`:

```bash
# ä½¿ç”¨DockeræœåŠ¡
ELASTICSEARCH_URL=http://localhost:9200
NEO4J_URI=bolt://localhost:7687
REDIS_URL=redis://localhost:6379
```

### ç”Ÿäº§ç¯å¢ƒé…ç½®

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  elasticsearch:
    # ... åŸºç¡€é…ç½® ...
    environment:
      # å¯ç”¨å®‰å…¨
      - xpack.security.enabled=true
      # å¢åŠ èµ„æº
      - "ES_JAVA_OPTS=-Xms4g -Xmx4g"
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
```

---

## ğŸ” æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

#### 1. Elasticsearchå¯åŠ¨å¤±è´¥

```bash
# æ£€æŸ¥æ—¥å¿—
docker logs onto-elasticsearch

# å¸¸è§åŸå› : vm.max_map_countè®¾ç½®è¿‡ä½
sudo sysctl -w vm.max_map_count=262144

# æ°¸ä¹…è®¾ç½®
echo "vm.max_map_count=262144" | sudo tee -a /etc/sysctl.conf
```

#### 2. Neo4jæ— æ³•è¿æ¥

```bash
# æ£€æŸ¥ç«¯å£
netstat -an | grep 7687

# æ£€æŸ¥è®¤è¯
docker exec onto-neo4j neo4j-admin dbms set-initial-password password123
```

#### 3. å®¹å™¨å†…å­˜ä¸è¶³

```yaml
# é™åˆ¶å†…å­˜ä½¿ç”¨
services:
  elasticsearch:
    mem_limit: 2g
    memswap_limit: 2g
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### å®˜æ–¹æ–‡æ¡£
- Elasticsearch: https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html
- Neo4j: https://neo4j.com/docs/operations-manual/current/docker/
- Redis: https://hub.docker.com/_/redis
- RabbitMQ: https://www.rabbitmq.com/download.html
- Jena Fuseki: https://jena.apache.org/documentation/fuseki2/

### æœ€ä½³å®è·µ
- Docker Composeæœ€ä½³å®è·µ: https://docs.docker.com/compose/production/
- å®¹å™¨ç›‘æ§: Prometheus + Grafana
- æ—¥å¿—èšåˆ: ELK Stack

---

## âœ… æ£€æŸ¥æ¸…å•

åœ¨å¼€å§‹æ–°Sprintä¹‹å‰ï¼Œç¡®è®¤ï¼š

- [ ] Dockerå’ŒDocker Composeå·²å®‰è£…
- [ ] å¿…è¦çš„ç«¯å£æœªè¢«å ç”¨
- [ ] æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ï¼ˆè‡³å°‘20GBï¼‰
- [ ] vm.max_map_countå·²è®¾ç½®ï¼ˆLinuxï¼‰
- [ ] docker-composeæ–‡ä»¶å·²åˆ›å»º
- [ ] ç¯å¢ƒå˜é‡å·²é…ç½®
- [ ] å¥åº·æ£€æŸ¥è„šæœ¬å¯ç”¨
- [ ] å¤‡ä»½ç­–ç•¥å·²åˆ¶å®š

---

**ğŸ‰ æ‰€æœ‰ç¬¬ä¸‰æ–¹æœåŠ¡å·²å®¹å™¨åŒ–ï¼Œé›¶æœ¬åœ°å®‰è£…ï¼**

**ä¸‹ä¸€æ­¥**: æ ¹æ®Sprinté˜¶æ®µï¼Œä½¿ç”¨å¯¹åº”çš„docker-composeæ–‡ä»¶å¯åŠ¨æœåŠ¡ã€‚

---

**åˆ›å»ºæ—¥æœŸ**: 2026-01-17  
**ç‰ˆæœ¬**: v1.0  
**ç»´æŠ¤**: éšSprintæ›´æ–°
